= Java Client
[[java-client]]

The Java client is **the most full featured** Hazelcast native client.
It is offered both with Hazelcast IMDG and Hazelcast IMDG Enterprise.
The main idea behind the Java client is to provide the same Hazelcast
functionality by proxying each operation through a Hazelcast member.
It can access and change distributed data and it can listen to distributed
events of an already established Hazelcast cluster from another Java application the link:https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config[Prometheus configuration documentation].

TIP: For guidance, see the link:https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config[Prometheus configuration documentation].

Content in document.

terminals in which the members are running or press kbd:[Ctrl+C] in each terminal.

image:cluster-connected.png[Cluster Connected]

Content in document

Content in document.

image:connect-cluster.png[]

Content in document


Hundreds or even thousands of clients can be connected to the cluster.
By default, there are `core count * 20` threads on the server side that
handle all the requests, e.g., if the server has 4 cores, there will be 80 threads.

Imagine a trading application where all the trading data are stored and
managed in a Hazelcast cluster with tens of members. Swing/Web applications
at the traders' desktops can use clients to access and modify the data in the Hazelcast cluster.

== Getting Started with Java Client

NOTE: You do not need to set a license key for your Java clients for which you want to
use Hazelcast IMDG Enterprise features. Hazelcast IMDG Enterprise license keys are
required only for members.

Imagine a trading application where all the trading data are stored and
managed in a Hazelcast cluster with tens of members.

== Getting Started with Java Client

TIP: You do not need to set a license key for your Java clients for which you want to
use Hazelcast IMDG Enterprise features. Hazelcast IMDG Enterprise license keys are
required only for members.

Imagine a trading application where all the trading data are stored and
managed in a Hazelcast cluster with tens of members.

== Getting Started with Java Client

IMPORTANT: You do not need to set a license key for your Java clients for which you want to
use Hazelcast IMDG Enterprise features. Hazelcast IMDG Enterprise license keys are
required only for members.

Imagine a trading application where all the trading data are stored and
managed in a Hazelcast cluster with tens of members.

== Getting Started with Java Client

CAUTION: You do not need to set a license key for your Java clients for which you want to
use Hazelcast IMDG Enterprise features. Hazelcast IMDG Enterprise license keys are
required only for members.

Imagine a trading application where all the trading data are stored and
managed in a Hazelcast cluster with tens of members.

== Getting Started with Java Client or Maybe some other client

WARNING: You do not need to set a license key for your Java clients for which you want to
use Hazelcast IMDG Enterprise features. Hazelcast IMDG Enterprise license keys are
required only for members.


== Getting Started with Java Client

NOTE: You do not need to set a license key for your Java clients for which you want to
use Hazelcast IMDG Enterprise features. Hazelcast IMDG Enterprise license keys are
required only for members.

Imagine a trading application where all the trading data are stored and
managed in a Hazelcast cluster with tens of members.

== Getting Started with Java Client

TIP: You do not need to set a license key for your Java clients for which you want to
use Hazelcast IMDG Enterprise features. Hazelcast IMDG Enterprise license keys are
required only for members.

Imagine a trading application where all the trading data are stored and
managed in a Hazelcast cluster with tens of members.

== Getting Started with Java Client

IMPORTANT: You do not need to set a license key for your Java clients for which you want to
use Hazelcast IMDG Enterprise features. Hazelcast IMDG Enterprise license keys are
required only for members.

Imagine a trading application where all the trading data are stored and
managed in a Hazelcast cluster with tens of members.

== Getting Started with Java Client

CAUTION: You do not need to set a license key for your Java clients for which you want to
use Hazelcast IMDG Enterprise features. Hazelcast IMDG Enterprise license keys are
required only for members.

Imagine a trading application where all the trading data are stored and
managed in a Hazelcast cluster with tens of members.

== Getting Started with Java Client

WARNING: You do not need to set a license key for your Java clients for which you want to
use Hazelcast IMDG Enterprise features. Hazelcast IMDG Enterprise license keys are
required only for members.


== Getting Started with Java Client

Simply include the `hazelcast.jar` dependency in your classpath to start using
the Hazelcast Java client. Once included, you can start using this client as if
you are using the Hazelcast API. The differences are discussed in the below sections.

== Getting Started with Java Client

If you prefer to use Maven, simply add the `hazelcast` dependency
to your `pom.xml`, which you may already have done to start using
Hazelcast IMDG:

[source,xml,subs="attributes+"]
----
<dependency>
    <groupId>com.hazelcast</groupId>
    <artifactId>hazelcast</artifactId>
    <version>{page-component-display-version}</version>
</dependency>
----

You can find Hazelcast Java client's code samples https://github.com/hazelcast/hazelcast-code-samples/tree/master/clients[here^].

=== Client API

The first step is the configuration. You can configure the Java client declaratively or
programmatically. We use the programmatic approach for this section, as shown below.

[source,java]
----
ClientConfig clientConfig = new ClientConfig();
clientConfig.setClusterName("dev");
clientConfig.getNetworkConfig().addAddress("10.90.0.1", "10.90.0.2:5702");
----

See the <<configuring-java-client, Configuring Java Client section>> for more information.

== Getting Started with Java Client

The second step is initializing the `HazelcastInstance` to be connected to the cluster.

```
HazelcastInstance client = HazelcastClient.newHazelcastClient(clientConfig);
```

*This client interface is your gateway to access all Hazelcast distributed objects.*

Let's create a map and populate it with some data.

== Getting Started with Java Client

[source,java]
----
IMap<String, Customer> mapCustomers = client.getMap("customers"); //creates the map proxy

mapCustomers.put("1", new Customer("Joe", "Smith"));
mapCustomers.put("2", new Customer("Ali", "Selam"));
mapCustomers.put("3", new Customer("Avi", "Noyan"));
----

== Getting Started with Java Client

As the final step, if and when you are done with your client, you can shut it down as shown below:

```
client.shutdown();
```


== Test code source with annotations

You'll start the first member in a cluster called `hello-world`. Run the following Docker command:

[source,shell,subs="attributes+"]
----
docker run \
    --name first-member --network hazelcast-network \
    --rm \
    -e HZ_NETWORK_PUBLICADDRESS=<host_ip>:5701 \ <1>
    -e HZ_CLUSTERNAME=hello-world \
    -e HZ_LICENSEKEY=<your license key> \ <2>
    -e HZ_PERSISTENCE_ENABLED=true \ <3>
    -e HZ_MAP_MYDISTRIBUTEDMAP_DATAPERSISTENCE_ENABLED=true \ <4>
    -v ~/persist:/opt/hazelcast/persistence \ <5>
    -p 5701:5701 hazelcast/hazelcast-enterprise:{ee-version}
----
<1> Replace the `<host_ip>` placeholder with the IP address of your Docker host.
<2> Replace the `<your license key>` placeholder with your Hazelcast {enterprise-product-name} license key.
<3> The environment variable to enable the persistence feature for the member
<4> The environment variable to enable the persistence feature for a map
<5> By default, the persistence feature creates the `/opt/hazelcast/persistence` directory to store the persisted data.
However, using a Docker image, you cannot create any files inside the container. This line of the command mounts a directory
on your local to the container, which in this case is `persist` under the home directory. This way, the container will use this local
directory to save the persisted data.


|===
|Column 1 |Column 2 |Column 3

^.>|The specifier for this cell is `^.>`.
The content is centered horizontally and aligned to the bottom of the cell.
|There aren't any alignment operators on this cell's specifier, so the cell falls back to the default alignments.
The default horizontal alignment is the left side of the cell.
The default vertical alignment is the top of the cell.
>.^|The specifier for this cell is `>.^`.
The content is aligned to the right side of the cell and centered vertically.

2.3+^.^|The specifier for this cell is `pass:[2.3+^.^]`.
It spans two columns and three rows.

Its content is centered horizontally and vertically.
3*.>|The specifier for this cell is `3*.>`.
The cell is duplicated in three consecutive rows in the same column.
It's content is aligned to the bottom of the cell.
|===


== Key features and benefits

[cols="<30%,<15%,<15%,<40%", options="header"]
|===
|[align=left]*Core Hazelcast Capabilities*|[align=left]*{enterprise-product-name}*|[align=left]*{open-source-product-name}*|[align=left]*Description*

|Distributed data storage: AP data structures
|&#9989;
|&#9989;
|Store and manage distributed data with high availability and partition tolerance via IMap, IQueue, ITopic, ISet, IList, MultiMap, Ringbuffer, etc. For more information, see xref:data-structures:distributed-data-structures.adoc[].

|Advanced caching strategies
|&#9989;
|&#9989;
|Intelligent caching including write-through, write-behind, and refresh-ahead policies via MapStore and MapLoader interfaces. For more information, see xref:mapstore:working-with-external-data.adoc[].

|Distributed data storage: CP data structures
|&#9989;
|&#10060;
|Ensure strong consistency for critical data using CP data structures powered by the Raft consensus algorithm via CPMap, FencedLock, IAtomicLong, IAtomicReference, ICountDownLatch, and ISemaphore. For more information, see xref:data-structures:cpmap.adoc[].

|Change Data Capture (CDC) connectors
|&#9989;
|&#10060;
|Streams real-time data changes from various databases directly into Hazelcast, enabling immediate processing and synchronization for up-to-date insights and applications. For more information, see xref:pipelines:cdc-overview.adoc[].

|Out-of-the-Box connectors for other platforms
|&#9989;
|&#9989;
|Seamlessly connect to a wide range of popular data platforms, including Apache Kafka, MongoDB, MySQL, Elasticsearch, Amazon Kinesis, Apache Pulsar, and Hadoop—using built-in connector APIs for effortless data integration and movement. For more information, see xref:integrate:connectors.adoc[].

|Integration with frameworks
|&#9989;
|&#9989;
|Easily integrate with leading frameworks, including Spring, Spring Boot, Hibernate, Feast, and Vert.x. Includes robust session replication support for Tomcat, Jetty, and generic web session managers. For more information, see xref:spring:overview.adoc[].

|Client libraries
|&#9989;
|&#9989;
|Choose from Java, .NET, C++, Python, Node.js, and Go client libraries with smart client capabilities and near cache support. For more information, see xref:clients:hazelcast-clients.adoc[].

|REST API
|&#9989;
|&#10060;
|Includes a comprehensive REST API for managing and monitoring Hazelcast clusters, enabling operations such as cluster state changes, member management, and access to detailed cluster metrics and diagnostics. For more information, see xref:maintain-cluster:enterprise-rest-api.adoc[].

|*Strong consistency*|*{enterprise-product-name}*|*{open-source-product-name}*|*Description*
|CP Subsystem persistence
|&#9989;
|&#10060;
|Quickly recover consistent data structures after cluster-wide outages. For more information, see xref:cp-subsystem:configuration.adoc#persistence[Persist CP data structures].

|CP leadership placement control
|&#9989;
|&#10060;
|Enables you to define which members become CP leaders using a variety of methods, including by IP address. For more information, see xref:cp-subsystem:configuration#configuring-leadership-priority.adoc[Configure leadership priority].
//check terminology of placement control vs leadership priority, and release status

|*Advanced compute and processing*|*{enterprise-product-name}*|*{open-source-product-name}*|*Description*
|Distributed compute
|&#9989;
|&#9989;
|Execute distributed computations and parallel processing across the cluster using entry processors and listeners. For more information, see xref:computing:distributed-computing.adoc[].

|SQL querying
|&#9989;
|&#10060;
|Query and analyze data using standard SQL syntax for real-time insights (via Jet Engine). For more information, see xref:sql:sql-overview.adoc[].

|Command Line Client (CLC): SQL querying
|&#9989;
|&#9989;
|Executes SQL queries against your cluster and displays the output as a table or in a variety of text formats, such as JSON and CSV. For more information, see xref:{page-latest-supported-clc}@clc::clc-sql.adoc[`clc sql`].

|SQL permissions and security
|&#9989;
|&#10060;
|Provides fine-grained authorization for SQL permissions and security, allowing control over which clients can execute specific SQL statements and access certain resources when security is enabled. For more information, see xref:sql:sql-overview.adoc#permissions[Permissions and security].

|Stream processing
|&#9989;
|&#9989;
|Build and run real-time data pipelines for event-driven applications using the Jet Engine. For more information, see xref:pipelines:building-pipelines.adoc[]

|Jet job placement control
|&#9989;
|&#10060;
|Isolate compute from storage workloads and target specific cluster nodes for optimized resource utilization in stream processing jobs. Enables compute functions to be scaled independently of storage. For more information, see xref:pipelines:job-management.adoc[]

|Jet lossless recovery
|&#9989;
|&#10060;
|Recover stream processing jobs from a site-wide disaster without any data loss. For more information, see xref:storage:configuring-persistence.adoc[].

|Jet rolling job upgrade
|&#9989;
|&#10060;
|Seamlessly upgrade a running stream processing job with no downtime and no data loss. For more information, see xref:pipelines:job-update.adoc[].

|User code namespaces
|&#9989;
|&#10060;
|Isolate and manage different versions of application code (such as classes or JARs) within a single cluster, preventing conflicts and ensuring that applications or modules run independently without interference. For more information, see xref:clusters:user-code-namespaces.adoc[].

|Advanced multi-member routing
|&#9989;
|&#10060;
|Get enhanced performance for geographically dispersed clusters with intelligent client routing and load distribution. For more information, see xref:clients:java.adoc#client-cluster-routing-modes[Client cluster routing modes]

|Vector Search (BETA)
|&#9989;
|&#10060;
|Efficiently process and search high-dimensional vector data for AI and ML workloads. For more information, see xref:data-structures:vector-search-tutorial.adoc[].

|*Cloud native*|*{enterprise-product-name}*|*{open-source-product-name}*|*Description*
|Cloud provider integration
|&#9989;
|&#9989;
|Native integration with AWS, Azure, and GCP services and APIs. For more information, see xref:deploy:deploying-in-cloud.adoc[].

|Hazelcast Operator for Kubernetes
|&#9989;
|&#10060;
|Automate deployment and management of Hazelcast clusters on Kubernetes with advanced features. For more information, see https://docs.hazelcast.com/operator/latest[Hazelcast Operator docs].

|Helm charts
|&#9989;
|&#9989;
|Deploy Hazelcast clusters using Helm charts that support Enterprise features and security configurations. For more information, see xref:kubernetes:helm-hazelcast-chart.adoc[].
// double check

|OpenShift support
|&#9989;
|&#10060;
|Certified deployment support for Red Hat OpenShift with security scanning and platform integration.

|*Security*|*{enterprise-product-name}*|*{open-source-product-name}*|*Description*
|Emergency patches (CVEs)
|&#9989;
|&#10060;
|Receive urgent security and bug fixes promptly to minimize risk exposure.

|Authentication and authorization (JAAS)
|&#9989;
|&#10060;
|Java Authentication and Authorization Service integration with LDAP, Active Directory, Kerberos, and X.509 certificate-based authentication. For more information, see xref:security:jaas-authentication.adoc[].

|Role-Based Access Control (RBAC)
|&#9989;
|&#10060;
|Granular permission policies for data structures and operations based on client roles, endpoints, and principals with wildcard support. For more information, see xref:{page-latest-supported-mc}@management-center:deploy-manage:user-management.adoc[].

|SSL/TLS Encryption
|&#9989;
|&#10060;
|End-to-end TLS encryption for all member-to-member and client-to-member communications with configurable cipher suites with TLS support. For more information, see xref:security:tls-ssl.adoc[].

|TLS mutual authentication
|&#9989;
|&#10060;
|Enable each side of a connection to provide identity via X.509 certificates. For more information, see xref:security:tls-ssl.adoc#mutual-authentication[Mutual authentication].

|Audit Logging
|&#9989;
|&#10060;
|Comprehensive logging of security events, cluster operations, authentication attempts, and user actions for compliance and monitoring. For more information, see xref:security:logging-auditable-events.adoc[].

|Socket interceptor
|&#9989;
|&#10060;
|Add custom security checks for client connections to the cluster. For more information, see xref:security:socket-interceptor.adoc[].

|Security interceptor
|&#9989;
|&#10060;
|Enforce fine-grained security policies on remote operations and data access. For more information, see xref:security:socket-interceptor.adoc[].

|*High availability*|*{enterprise-product-name}*|*{open-source-product-name}*|*Description*

|WAN Replication
|&#9989;
|&#10060;
|Cross-cluster geo replication synchronization with active-active/active-passive modes, delta synchronization using Merkle Trees, and configurable batch processing for geographic distribution. Management Center provides detailed metrics and management. For more information, see xref:getting-started:wan-replication-tutorial.adoc[].

|Hot restart persistence
|&#9989;
|&#10060;
|Fast cluster restart with log-structured storage optimized for SSD. For more information, see xref:storage:persistence.adoc[].

|Dynamic config persistence
|&#9989;
|&#10060;
|Retain configuration changes across restarts and outages. For more information, see xref:configuration:dynamic-config-persistence.adoc[].

|Rolling upgrades
|&#9989;
|&#10060;
|Zero-downtime cluster upgrades allow seamless version transitions without service interruption or data loss. Management Center enables monitoring and management of rolling upgrades. For more information, see xref:maintain-cluster:rolling-upgrades.adoc[].

|Blue/Green deployments
|&#9989;
|&#10060;
|Client filtering capabilities enable blue/green deployment strategies with controlled client connection management. Management Center enables you to control which clients can connect to a cluster. For more information, see xref:getting-started:deploy-blue-green-tutorial.adoc[].

|*High performance and scaling*|*{enterprise-product-name}*|*{open-source-product-name}*|*Description*

|High-Density memory store
|&#9989;
|&#10060;
|Store more data per member with off-heap memory for greater scale and efficiency. For more information, see xref:storage:high-density-memory.adoc[].

|External backup support
|&#9989;
|&#10060;
|Hazelcast Platform Operator enables automatic backup to cloud storage providers (S3, GCS, Azure) with configurable retention policies and disaster recovery capabilities. For more information, see https://docs.hazelcast.com/operator/latest/backup-restore#triggering-external-backups[Trigger external backups].

|Thread-Per-Core (TPC) engine
|&#9989;
|&#10060;
|Maximize performance by dedicating threads to CPU cores and reducing context switching. For more information, see xref:cluster-performance:thread-per-core-tpc.adoc[].

|*Real-Time monitoring and performance tracking*|*{enterprise-product-name}*|*{open-source-product-name}*|*Description*
|Management Center
|&#9989;
|&#10060;
|Get full access to all Management Center features, including advanced security, monitoring, and management features. {open-source-product-name} offers basic functionality for small deployments (up to 3 cluster members). For more information, see xref:{page-latest-supported-mc}@management-center:getting-started:overview.adoc[Management Center Overview].

|Clustered JMX and REST
|&#9989;
|&#10060;
|Provides clustered JMX and REST interfaces for unified management and monitoring of Hazelcast clusters, enabling remote access to metrics, operations, and diagnostics across all cluster members for streamlined integration with external monitoring and management tools. Includes Client Filtering API, Cluster Metrics API, Cluster Connections API, and WAN Replication API. For more information, see xref:{page-latest-supported-mc}@management-center:integrate:jmx.adoc[JMX].

|*Powerful administrative tools*|*{enterprise-product-name}*|*{open-source-product-name}*|*Description*
// minus MC features is this section viable?
|Command Line Client (CLC)
|&#9989;
|&#9989;
|Connects to and interacts with Hazelcast clusters directly from the command line or through scripts. Empowers you to run SQL queries, create data pipelines, access data for debugging, and automate repetitive administration, integration, or testing tasks through scripting. An essential tool for efficient cluster management, automation, and troubleshooting in both development and production environments. For more information, see xref:{page-latest-supported-clc}@clc::overview.adoc[Command Line Client (CLC)].

|*Support and maintenance*|*{enterprise-product-name}*|*{open-source-product-name}*|*Description*

|24/7 professional support
|&#9989;
|&#10060;
|Round-the-clock technical support with 1-hour SLA for critical issues, technical account management, and hot fix patches.

|CVE patch releases
|&#9989;
|&#10060;
|Security vulnerability patches delivered as regular patch releases ({open-source-product-name} only updated in major/minor releases, no patches).

|Professional training
|&#9989;
|&#10060;
|Three-tier certification program, instructor-led training, customized workshops, and solution architect support.
// double check

|===
